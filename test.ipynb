{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "\n",
    "def set_seed(seed=777):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Seed 고정\n",
    "set_seed(777)\n",
    "\n",
    "\n",
    "#####################\n",
    "# YOU MUST WRITE YOUR STUDENT ID IN THE VARIABLE STUDENT_ID\n",
    "# EXAMPLE: STUDENT_ID = \"12345678\"\n",
    "#####################\n",
    "STUDENT_ID = \"20251189\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df1, df2):\n",
    "    # BUT you should keep the file name as \"{STUDENT_ID}_simple_seq.p#.answer.csv\"\n",
    "    df1.to_csv(f'{STUDENT_ID}_simple_seq.p1.answer.csv')\n",
    "    df2.to_csv(f'{STUDENT_ID}_simple_seq.p2.answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.W = torch.nn.Parameter(torch.empty(in_features, out_features, dtype=torch.float32))\n",
    "        self.b = torch.nn.Parameter(torch.empty(out_features, dtype=torch.float32))\n",
    "        \n",
    "        # Xavier 초기화 적용\n",
    "        init.xavier_uniform_(self.W)\n",
    "        init.zeros_(self.b)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.mm(self.W) + self.b\n",
    "\n",
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layer1 = CustomLinear(input_dim, 1000)\n",
    "        self.layer2 = CustomLinear(1000, 100)\n",
    "        self.layer3 = CustomLinear(100, 19)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1.forward(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2.forward(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer3.forward(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2     3     4    5    6     7     8     9    10    11    12  \\\n",
      "0   W25   W26   W27   W19   W28  W29  W30   W31   W32   W33  W34   W35   W36   \n",
      "1   W41    W4   W42   W43   W44  W45  W46   W47   W48   W49  W50   W51   W52   \n",
      "2   W55   W19   W46   W32   W32  W56  W57   W58   W59   W19  W13   W60   W19   \n",
      "3   W13   W83   W32   W32   W56  W57  W13   W84   W19   W28  W85   W86   W24   \n",
      "4   W87   W88   W89   W90   W32  W91  W13   W92   W93   W90  W94   W95   W24   \n",
      "5   W13   W52   W32   W53   W17  W13  W96   W97   W10    W2  W98   W99   W19   \n",
      "6  W122  W123  W110  W124  W125  W19  W13  W126  W127  W128  W32  W129  W130   \n",
      "\n",
      "    13    14    15    16   17    18   19  \n",
      "0  W37   W38   W39   W24  W40   PAD  PAD  \n",
      "1  W53   W17   W54   W24  PAD   PAD  PAD  \n",
      "2  W13   W61   W62   PAD  PAD   PAD  PAD  \n",
      "3  PAD   PAD   PAD   PAD  PAD   PAD  PAD  \n",
      "4  PAD   PAD   PAD   PAD  PAD   PAD  PAD  \n",
      "5  W13  W100   W24   PAD  PAD   PAD  PAD  \n",
      "6  W36   W13  W131  W132  W17  W133  W24  \n",
      "  true_label\n",
      "0        D11\n",
      "1         D1\n",
      "2         D3\n",
      "3        D20\n",
      "4        D20\n",
      "900\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "column_names = [f'{i}' for i in range(1, 22)]\n",
    "train = pd.read_csv('./dataset/simple_seq.train.csv', names=column_names)\n",
    "\n",
    "def extract_last_value(row):\n",
    "    non_nan_values = row.dropna().tolist() \n",
    "    return non_nan_values[-1]\n",
    "\n",
    "true_labels = train.apply(extract_last_value, axis=1) \n",
    "\n",
    "def remove_last_value(row):\n",
    "    non_nan_values = row.dropna().tolist()  \n",
    "    non_nan_values.pop()\n",
    "    return pd.Series(non_nan_values)\n",
    "\n",
    "train = train.apply(remove_last_value, axis=1) \n",
    "train.fillna(\"PAD\", inplace=True)\n",
    "\n",
    "true_labels_df = pd.DataFrame(true_labels, columns=[\"true_label\"])\n",
    "\n",
    "print(train.head(7))\n",
    "print(true_labels_df.head())\n",
    "print(len(train))\n",
    "print(len(true_labels_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1     2      3     4      5      6     7      8      9     10     11  \\\n",
      "0    W13   W81    W19  W346   W846  W1582   W70    W28  W5433    W19  W1163   \n",
      "1  W5413  W111  W5414   W32    W68  W5415   W12  W2402    W19  W5438  W5439   \n",
      "2  W5413  W111  W5414   W32    W68  W5415   W12   W417   W346   W336    W17   \n",
      "3  W5413  W111  W5414   W32    W68  W5415   W12   W346    W32  W2833    W93   \n",
      "4  W5413  W111  W5414   W32    W68  W5415   W12   W111   W346    W47   W336   \n",
      "5  W5413  W111  W5414   W32    W68  W5415   W12   W346   W168  W2464  W5448   \n",
      "6    W87   W31    W47   W38  W1196    W97  W627  W5449    PAD    PAD    PAD   \n",
      "\n",
      "      12     13     14     15     16     17    18     19   20  \n",
      "0  W2261    W24    PAD    PAD    PAD    PAD   PAD    PAD  PAD  \n",
      "1  W5440    W12   W346   W240  W5441  W5442   W24    PAD  PAD  \n",
      "2    W28  W5443    W12   W122    W47    W38  W335  W1248  W24  \n",
      "3    W28  W5444  W5445    W17   W346  W5446   W24    PAD  PAD  \n",
      "4   W286  W5415   W552  W5447   W641   W346   W24    PAD  PAD  \n",
      "5    W24    PAD    PAD    PAD    PAD    PAD   PAD    PAD  PAD  \n",
      "6    PAD    PAD    PAD    PAD    PAD    PAD   PAD    PAD  PAD  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_22484\\2865642782.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'PAD' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  test.fillna(\"PAD\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "column = [f'{i}' for i in range(1, 22)]\n",
    "test = pd.read_csv('./dataset/simple_seq.test.csv', header=None, names=column)\n",
    "test.fillna(\"PAD\", inplace=True)\n",
    "test.drop(columns=['21'], inplace=True)\n",
    "print(test.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2548\n",
      "['PAD', 'UNK', 'W1', 'W10', 'W100', 'W1003', 'W1004', 'W1008', 'W1009', 'W1010']\n",
      "19\n",
      "['D1', 'D11', 'D12', 'D13', 'D15', 'D16', 'D17', 'D18', 'D19', 'D20', 'D21', 'D27', 'D28', 'D3', 'D32', 'D4', 'D5', 'D6', 'D7']\n"
     ]
    }
   ],
   "source": [
    "unique_words= set(train.values.flatten()).union({\"UNK\"})\n",
    "vocab=sorted(list(unique_words))\n",
    "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "print(len(vocab))\n",
    "print(vocab[:10])\n",
    "\n",
    "unique_labels = set(true_labels_df['true_label'].values)\n",
    "label_vocab = sorted(list(unique_labels))\n",
    "label_to_index = {label: i for i, label in enumerate(label_vocab)}\n",
    "print(len(label_vocab))\n",
    "print(label_vocab[:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot_encode(row, vocab_size, word_to_index):\n",
    "#     one_hot_matrix = np.zeros((len(row), vocab_size))\n",
    "#     for i, word in enumerate(row):\n",
    "#         word = word if word in word_to_index else \"UNK\"\n",
    "#         if word != \"PAD\":\n",
    "#             one_hot_matrix[i, word_to_index[word]] = 1\n",
    "#     return one_hot_matrix\n",
    "\n",
    "def one_hot_encode_label(label, label_to_index):   \n",
    "    one_hot_matrix = np.zeros((1, len(label_vocab)))\n",
    "    one_hot_matrix[0, label_to_index[label]] = 1\n",
    "    return one_hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(row, vocab_size, word_to_index, max_seq_length=20):\n",
    "    word_indices = []\n",
    "    for word in row[:max_seq_length]:\n",
    "        word = word if word in word_to_index else \"UNK\"\n",
    "        word_indices.append(word_to_index[word])  \n",
    "    return word_indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 226.36210966932362\n",
      "Epoch 2, Loss: 2.907420857199307\n",
      "Epoch 3, Loss: 2.9153895213686187\n",
      "Epoch 4, Loss: 2.851698875427246\n",
      "Epoch 5, Loss: 2.847069559426143\n",
      "Epoch 6, Loss: 2.823448131824362\n",
      "Epoch 7, Loss: 2.9939020502156226\n",
      "Epoch 8, Loss: 2.850068947364544\n",
      "Epoch 9, Loss: 2.8209226789145636\n",
      "Epoch 10, Loss: 2.82082357899896\n",
      "Epoch 11, Loss: 2.812918243737056\n",
      "Epoch 12, Loss: 2.8442505556961586\n",
      "Epoch 13, Loss: 2.812787754782315\n",
      "Epoch 14, Loss: 2.805862911816301\n",
      "Epoch 15, Loss: 2.798146996004828\n",
      "Epoch 16, Loss: 2.794185317795852\n",
      "Epoch 17, Loss: 2.783752260536983\n",
      "Epoch 18, Loss: 2.748584434903901\n",
      "Epoch 19, Loss: 2.747150388257257\n",
      "Epoch 20, Loss: 2.7277306770456247\n",
      "Epoch 21, Loss: 2.7071708070820777\n",
      "Epoch 22, Loss: 2.7031356301800957\n",
      "Epoch 23, Loss: 2.6981079413973053\n",
      "Epoch 24, Loss: 2.6828941805609343\n",
      "Epoch 25, Loss: 2.64678562098536\n",
      "Epoch 26, Loss: 2.5917820930480957\n",
      "Epoch 27, Loss: 2.598069585602859\n",
      "Epoch 28, Loss: 2.616361502943368\n",
      "Epoch 29, Loss: 2.485735457519005\n",
      "Epoch 30, Loss: 2.524665824298201\n",
      "Epoch 31, Loss: 2.503555708918078\n",
      "Epoch 32, Loss: 2.4632609054960053\n",
      "Epoch 33, Loss: 2.4361102992090684\n",
      "Epoch 34, Loss: 2.445184563768321\n",
      "Epoch 35, Loss: 2.6417332846542885\n",
      "Epoch 36, Loss: 2.45653013525338\n",
      "Epoch 37, Loss: 2.337173971636542\n",
      "Epoch 38, Loss: 2.3969763311846504\n",
      "Epoch 39, Loss: 2.3580344134363633\n",
      "Epoch 40, Loss: 2.2329814187411605\n",
      "Epoch 41, Loss: 2.3057271242141724\n",
      "Epoch 42, Loss: 2.2278793269190293\n",
      "Epoch 43, Loss: 2.141437234549687\n",
      "Epoch 44, Loss: 2.0725743729492714\n",
      "Epoch 45, Loss: 2.0155358725580674\n",
      "Epoch 46, Loss: 1.9844691876707405\n",
      "Epoch 47, Loss: 1.9828300887140735\n",
      "Epoch 48, Loss: 1.998513205298062\n",
      "Epoch 49, Loss: 1.9045602987552512\n",
      "Epoch 50, Loss: 1.9123348285411965\n",
      "Epoch 51, Loss: 1.93834453615649\n",
      "Epoch 52, Loss: 1.8447537339966873\n",
      "Epoch 53, Loss: 1.7846537746232132\n",
      "Epoch 54, Loss: 1.7983952884016365\n",
      "Epoch 55, Loss: 1.7518540703017136\n",
      "Epoch 56, Loss: 1.759356272631678\n",
      "Epoch 57, Loss: 1.696086049079895\n",
      "Epoch 58, Loss: 1.7419562134249458\n",
      "Epoch 59, Loss: 1.7098897037834957\n",
      "Epoch 60, Loss: 1.7182373918336014\n",
      "Epoch 61, Loss: 1.7119818062617862\n",
      "Epoch 62, Loss: 1.628902992297863\n",
      "Epoch 63, Loss: 1.6281629184196735\n",
      "Epoch 64, Loss: 1.6281731786399052\n",
      "Epoch 65, Loss: 1.6032207752096241\n",
      "Epoch 66, Loss: 1.5979793318386735\n",
      "Epoch 67, Loss: 1.5885757618937\n",
      "Epoch 68, Loss: 1.610130264841277\n",
      "Epoch 69, Loss: 1.5693464875221252\n",
      "Epoch 70, Loss: 1.6068576574325562\n",
      "Epoch 71, Loss: 1.5982554534385944\n",
      "Epoch 72, Loss: 1.5452064275741577\n",
      "Epoch 73, Loss: 1.5681017842786065\n",
      "Epoch 74, Loss: 1.593306566106862\n",
      "Epoch 75, Loss: 1.5576178369850948\n",
      "Epoch 76, Loss: 1.5258008138886814\n",
      "Epoch 77, Loss: 1.577610365275679\n",
      "Epoch 78, Loss: 1.5497596510525407\n",
      "Epoch 79, Loss: 1.5359215654175857\n",
      "Epoch 80, Loss: 1.5401735059146224\n",
      "Epoch 81, Loss: 1.5095888540662568\n",
      "Epoch 82, Loss: 1.5239401521353886\n",
      "Epoch 83, Loss: 1.5244516422008645\n",
      "Epoch 84, Loss: 1.5161408720345333\n",
      "Epoch 85, Loss: 1.4922364045833718\n",
      "Epoch 86, Loss: 1.4897898353379349\n",
      "Epoch 87, Loss: 1.5169787776881252\n",
      "Epoch 88, Loss: 1.5009921419209447\n",
      "Epoch 89, Loss: 1.49430460765444\n",
      "Epoch 90, Loss: 1.5391005400953621\n",
      "Epoch 91, Loss: 1.4907794265911496\n",
      "Epoch 92, Loss: 1.5446560629482926\n",
      "Epoch 93, Loss: 1.4729189009502017\n",
      "Epoch 94, Loss: 1.480535967596646\n",
      "Epoch 95, Loss: 1.4551444218076508\n",
      "Epoch 96, Loss: 1.4860486079906594\n",
      "Epoch 97, Loss: 1.523986767078268\n",
      "Epoch 98, Loss: 1.489139330798182\n",
      "Epoch 99, Loss: 1.4856357779996148\n",
      "Epoch 100, Loss: 1.480079696096223\n",
      "Epoch 101, Loss: 1.5691685512148101\n",
      "Epoch 102, Loss: 1.464968282600929\n",
      "Epoch 103, Loss: 1.4950574225392834\n",
      "Epoch 104, Loss: 1.4707050857872799\n",
      "Epoch 105, Loss: 1.4643211816919262\n",
      "Epoch 106, Loss: 1.4667878520899806\n",
      "Epoch 107, Loss: 1.45160384013735\n",
      "Epoch 108, Loss: 1.4423126434457714\n",
      "Epoch 109, Loss: 1.4891174785022079\n",
      "Epoch 110, Loss: 1.4599055709510014\n",
      "Epoch 111, Loss: 1.4960372694607438\n",
      "Epoch 112, Loss: 1.4818229058693195\n",
      "Epoch 113, Loss: 1.4822458028793335\n",
      "Epoch 114, Loss: 1.4338553691732472\n",
      "Epoch 115, Loss: 1.4661509291879062\n",
      "Epoch 116, Loss: 1.4202509090818207\n",
      "Epoch 117, Loss: 1.481051490224641\n",
      "Epoch 118, Loss: 1.4297910599872983\n",
      "Epoch 119, Loss: 1.4333827248935043\n",
      "Epoch 120, Loss: 1.3932701030681873\n",
      "Epoch 121, Loss: 1.4101778803200558\n",
      "Epoch 122, Loss: 1.4074159901717613\n",
      "Epoch 123, Loss: 1.4446460584114338\n",
      "Epoch 124, Loss: 1.4147981281938224\n",
      "Epoch 125, Loss: 1.3781612412682895\n",
      "Epoch 126, Loss: 1.413180659557211\n",
      "Epoch 127, Loss: 1.3804480392357399\n",
      "Epoch 128, Loss: 1.3891275668966359\n",
      "Epoch 129, Loss: 1.4001250349242111\n",
      "Epoch 130, Loss: 1.3771416442147617\n",
      "Epoch 131, Loss: 1.373864905587558\n",
      "Epoch 132, Loss: 1.366409519623066\n",
      "Epoch 133, Loss: 1.5135809100907425\n",
      "Epoch 134, Loss: 1.3409381817127097\n",
      "Epoch 135, Loss: 1.3651362616440346\n",
      "Epoch 136, Loss: 1.352059610958757\n",
      "Epoch 137, Loss: 1.3408648207269867\n",
      "Epoch 138, Loss: 1.349117373598033\n",
      "Epoch 139, Loss: 1.3367667691460972\n",
      "Epoch 140, Loss: 1.367305591188628\n",
      "Epoch 141, Loss: 1.3186175946531624\n",
      "Epoch 142, Loss: 1.3643298601282055\n",
      "Epoch 143, Loss: 1.3143237623675117\n",
      "Epoch 144, Loss: 1.326274374435688\n",
      "Epoch 145, Loss: 1.2904528297227005\n",
      "Epoch 146, Loss: 1.305988570739483\n",
      "Epoch 147, Loss: 1.2861823295724804\n",
      "Epoch 148, Loss: 1.293887237022663\n",
      "Epoch 149, Loss: 1.3815226595977257\n",
      "Epoch 150, Loss: 1.3160018016552102\n",
      "Epoch 151, Loss: 1.3122865783757176\n",
      "Epoch 152, Loss: 1.2951580039386092\n",
      "Epoch 153, Loss: 1.3228467004052524\n",
      "Epoch 154, Loss: 1.3226925381298722\n",
      "Epoch 155, Loss: 1.3202611413495293\n",
      "Epoch 156, Loss: 1.2788376705399875\n",
      "Epoch 157, Loss: 1.3086214558831577\n",
      "Epoch 158, Loss: 1.3267660120437885\n",
      "Epoch 159, Loss: 1.2806224638018116\n",
      "Epoch 160, Loss: 1.302617218987695\n",
      "Epoch 161, Loss: 1.2878730276535297\n",
      "Epoch 162, Loss: 1.3251509584229568\n",
      "Epoch 163, Loss: 1.3452407676598122\n",
      "Epoch 164, Loss: 1.3209458630660484\n",
      "Epoch 165, Loss: 1.29107646078899\n",
      "Epoch 166, Loss: 1.3627636679287614\n",
      "Epoch 167, Loss: 1.2964889242731292\n",
      "Epoch 168, Loss: 1.2884408728829746\n",
      "Epoch 169, Loss: 1.3209166896754299\n",
      "Epoch 170, Loss: 2.0179297800721794\n",
      "Epoch 171, Loss: 1.3297856655614129\n",
      "Epoch 172, Loss: 1.3079536248897683\n",
      "Epoch 173, Loss: 1.2691810459926212\n",
      "Epoch 174, Loss: 1.2580204462182933\n",
      "Epoch 175, Loss: 1.2665293894965073\n",
      "Epoch 176, Loss: 1.2268127634607513\n",
      "Epoch 177, Loss: 1.3847901122323398\n",
      "Epoch 178, Loss: 1.2607228139351154\n",
      "Epoch 179, Loss: 1.2464005268853287\n",
      "Epoch 180, Loss: 1.252534685463741\n",
      "Epoch 181, Loss: 1.306729037186195\n",
      "Epoch 182, Loss: 1.261918106983448\n",
      "Epoch 183, Loss: 1.2413725565219749\n",
      "Epoch 184, Loss: 1.2836286754443729\n",
      "Epoch 185, Loss: 1.2519404435979908\n",
      "Epoch 186, Loss: 1.2696935842777122\n",
      "Epoch 187, Loss: 1.2468618956105462\n",
      "Epoch 188, Loss: 1.2448634587485214\n",
      "Epoch 189, Loss: 1.2653264711643089\n",
      "Epoch 190, Loss: 1.242186871068231\n",
      "Epoch 191, Loss: 1.226869157676039\n",
      "Epoch 192, Loss: 1.2271525284339642\n",
      "Epoch 193, Loss: 1.2450598252230678\n",
      "Epoch 194, Loss: 1.2319229738465671\n",
      "Epoch 195, Loss: 1.2267390469024921\n",
      "Epoch 196, Loss: 1.2417073866416668\n",
      "Epoch 197, Loss: 1.2790802018395786\n",
      "Epoch 198, Loss: 1.2719470755807285\n",
      "Epoch 199, Loss: 1.2354120303844582\n",
      "Epoch 200, Loss: 1.2253332384701432\n",
      "Epoch 201, Loss: 1.2213143439128482\n",
      "Epoch 202, Loss: 1.2339886488585636\n",
      "Epoch 203, Loss: 1.2381977541693325\n",
      "Epoch 204, Loss: 1.2028893807838703\n",
      "Epoch 205, Loss: 1.2160091009633294\n",
      "Epoch 206, Loss: 1.1705488685903878\n",
      "Epoch 207, Loss: 1.200861131322795\n",
      "Epoch 208, Loss: 1.2086969922328819\n",
      "Epoch 209, Loss: 1.207991990549811\n",
      "Epoch 210, Loss: 1.1913194553605442\n",
      "Epoch 211, Loss: 1.209669370075752\n",
      "Epoch 212, Loss: 1.2676093434465343\n",
      "Epoch 213, Loss: 1.17130511793597\n",
      "Epoch 214, Loss: 1.2364621491267764\n",
      "Epoch 215, Loss: 1.2765151981649727\n",
      "Epoch 216, Loss: 1.2406583901109367\n",
      "Epoch 217, Loss: 1.2085259207363785\n",
      "Epoch 218, Loss: 1.1958445516125908\n",
      "Epoch 219, Loss: 1.2145921094664212\n",
      "Epoch 220, Loss: 1.171693912867842\n",
      "Epoch 221, Loss: 1.1790075610423911\n",
      "Epoch 222, Loss: 1.1790368351443061\n",
      "Epoch 223, Loss: 1.1707770557239139\n",
      "Epoch 224, Loss: 1.1746239045570637\n",
      "Epoch 225, Loss: 1.2372187992622112\n",
      "Epoch 226, Loss: 1.1862188146032135\n",
      "Epoch 227, Loss: 1.1773605552212945\n",
      "Epoch 228, Loss: 1.1713224443896064\n",
      "Epoch 229, Loss: 1.1382355361149228\n",
      "Epoch 230, Loss: 1.1537390392402123\n",
      "Epoch 231, Loss: 1.1431814247164234\n",
      "Epoch 232, Loss: 1.201808828732063\n",
      "Epoch 233, Loss: 1.1517512161156227\n",
      "Epoch 234, Loss: 1.166738002464689\n",
      "Epoch 235, Loss: 1.1526671771345467\n",
      "Epoch 236, Loss: 1.124474613830961\n",
      "Epoch 237, Loss: 1.1348469956167813\n",
      "Epoch 238, Loss: 1.142369241550051\n",
      "Epoch 239, Loss: 1.2163659971335838\n",
      "Epoch 240, Loss: 1.119151820396555\n",
      "Epoch 241, Loss: 1.165405980471907\n",
      "Epoch 242, Loss: 1.2909613128366142\n",
      "Epoch 243, Loss: 1.1155651129525284\n",
      "Epoch 244, Loss: 1.1355547946074913\n",
      "Epoch 245, Loss: 1.2507186984193737\n",
      "Epoch 246, Loss: 1.1535440991664756\n",
      "Epoch 247, Loss: 1.14915951161549\n",
      "Epoch 248, Loss: 1.1195164692812953\n",
      "Epoch 249, Loss: 1.2022449209772308\n",
      "Epoch 250, Loss: 1.1143330109530483\n",
      "Epoch 251, Loss: 1.1564068917570443\n",
      "Epoch 252, Loss: 1.1342286960832004\n",
      "Epoch 253, Loss: 1.1309117777594204\n",
      "Epoch 254, Loss: 1.1343514467107838\n",
      "Epoch 255, Loss: 1.0960259858904213\n",
      "Epoch 256, Loss: 1.1300567943474342\n",
      "Epoch 257, Loss: 1.0815044559281448\n",
      "Epoch 258, Loss: 1.1412269514182518\n",
      "Epoch 259, Loss: 1.1099586363496452\n",
      "Epoch 260, Loss: 1.1368367158133408\n",
      "Epoch 261, Loss: 1.0964595182188626\n",
      "Epoch 262, Loss: 1.1557476849391544\n",
      "Epoch 263, Loss: 1.1610705153695469\n",
      "Epoch 264, Loss: 1.0590257439120063\n",
      "Epoch 265, Loss: 1.0955323885227073\n",
      "Epoch 266, Loss: 1.1153727872618313\n",
      "Epoch 267, Loss: 1.077563450254243\n",
      "Epoch 268, Loss: 1.0803478462942715\n",
      "Epoch 269, Loss: 1.0987024985510727\n",
      "Epoch 270, Loss: 1.095379923952037\n",
      "Epoch 271, Loss: 1.0604812379541069\n",
      "Epoch 272, Loss: 1.0665311792801166\n",
      "Epoch 273, Loss: 1.0757924051120364\n",
      "Epoch 274, Loss: 1.068993081306589\n",
      "Epoch 275, Loss: 1.0692576457714211\n",
      "Epoch 276, Loss: 1.1099902268113762\n",
      "Epoch 277, Loss: 1.0831501401703933\n",
      "Epoch 278, Loss: 1.0655553957511639\n",
      "Epoch 279, Loss: 1.1004244335766495\n",
      "Epoch 280, Loss: 1.0977102620848294\n",
      "Epoch 281, Loss: 1.1394319544578422\n",
      "Epoch 282, Loss: 1.057322656286174\n",
      "Epoch 283, Loss: 1.0776533032285756\n",
      "Epoch 284, Loss: 1.0354361123052136\n",
      "Epoch 285, Loss: 1.0548738056215747\n",
      "Epoch 286, Loss: 1.465982905749617\n",
      "Epoch 287, Loss: 1.114513703461351\n",
      "Epoch 288, Loss: 1.0607059680182358\n",
      "Epoch 289, Loss: 1.0325227071499001\n",
      "Epoch 290, Loss: 1.0510145199709926\n",
      "Epoch 291, Loss: 1.0588887683276473\n",
      "Epoch 292, Loss: 1.0231622251971015\n",
      "Epoch 293, Loss: 1.0287748349123989\n",
      "Epoch 294, Loss: 1.0258664077725903\n",
      "Epoch 295, Loss: 1.0215634230909676\n",
      "Epoch 296, Loss: 1.022074413710627\n",
      "Epoch 297, Loss: 1.0047280942571575\n",
      "Epoch 298, Loss: 1.0258679759913478\n",
      "Epoch 299, Loss: 1.030466768248328\n",
      "Epoch 300, Loss: 1.0149751860519935\n",
      "Epoch 301, Loss: 1.097145929418761\n",
      "Epoch 302, Loss: 1.0262950186071724\n",
      "Epoch 303, Loss: 1.0482821238451991\n",
      "Epoch 304, Loss: 1.0171673893928528\n",
      "Epoch 305, Loss: 1.0525378358775173\n",
      "Epoch 306, Loss: 1.0153744405713574\n",
      "Epoch 307, Loss: 1.0528618467265163\n",
      "Epoch 308, Loss: 1.0005986022538151\n",
      "Epoch 309, Loss: 1.0113795543539112\n",
      "Epoch 310, Loss: 1.0056550173923886\n",
      "Epoch 311, Loss: 1.0069389651561607\n",
      "Epoch 312, Loss: 1.0031268041709374\n",
      "Epoch 313, Loss: 0.9929405718014158\n",
      "Epoch 314, Loss: 0.9862232557658491\n",
      "Epoch 315, Loss: 0.9678726365854\n",
      "Epoch 316, Loss: 0.9790798117374552\n",
      "Epoch 317, Loss: 0.9688759014524263\n",
      "Epoch 318, Loss: 0.9445860447554753\n",
      "Epoch 319, Loss: 0.9511850948991447\n",
      "Epoch 320, Loss: 0.9494426373777718\n",
      "Epoch 321, Loss: 0.9417403545872919\n",
      "Epoch 322, Loss: 1.0369596912943084\n",
      "Epoch 323, Loss: 1.34043314539153\n",
      "Epoch 324, Loss: 1.0005600472976421\n",
      "Epoch 325, Loss: 1.0182638702721432\n",
      "Epoch 326, Loss: 0.9967259682458023\n",
      "Epoch 327, Loss: 0.9621266470900898\n",
      "Epoch 328, Loss: 0.9737916691549893\n",
      "Epoch 329, Loss: 0.9507347663928722\n",
      "Epoch 330, Loss: 0.9655306174837309\n",
      "Epoch 331, Loss: 0.9814161637733723\n",
      "Epoch 332, Loss: 0.9798093808108362\n",
      "Epoch 333, Loss: 1.043094408923182\n",
      "Epoch 334, Loss: 0.9787098313200062\n",
      "Epoch 335, Loss: 1.0031531802539169\n",
      "Epoch 336, Loss: 0.9772571674708662\n",
      "Epoch 337, Loss: 0.958069384098053\n",
      "Epoch 338, Loss: 0.9419982433319092\n",
      "Epoch 339, Loss: 0.994010187428573\n",
      "Epoch 340, Loss: 0.9426456998134481\n",
      "Epoch 341, Loss: 0.9353630666075081\n",
      "Epoch 342, Loss: 0.9513952321019666\n",
      "Epoch 343, Loss: 1.6737312191519245\n",
      "Epoch 344, Loss: 1.0033866495921695\n",
      "Epoch 345, Loss: 1.0477140586951683\n",
      "Epoch 346, Loss: 0.993798553943634\n",
      "Epoch 347, Loss: 0.9751813740565859\n",
      "Epoch 348, Loss: 0.9703462493830713\n",
      "Epoch 349, Loss: 0.9644329979501921\n",
      "Epoch 350, Loss: 0.9210115732817814\n",
      "Epoch 351, Loss: 0.9069740854460617\n",
      "Epoch 352, Loss: 0.9036080508396543\n",
      "Epoch 353, Loss: 0.947014736718145\n",
      "Epoch 354, Loss: 0.9178194013135187\n",
      "Epoch 355, Loss: 0.9136710187484478\n",
      "Epoch 356, Loss: 0.8883030722881186\n",
      "Epoch 357, Loss: 0.8724658108990768\n",
      "Epoch 358, Loss: 0.9202973760407547\n",
      "Epoch 359, Loss: 0.9196834749188917\n",
      "Epoch 360, Loss: 0.9289055661908512\n",
      "Epoch 361, Loss: 0.8829858508603327\n",
      "Epoch 362, Loss: 0.9385564861626461\n",
      "Epoch 363, Loss: 0.9107425356733387\n",
      "Epoch 364, Loss: 1.0440521805450833\n",
      "Epoch 365, Loss: 0.9395928937813331\n",
      "Epoch 366, Loss: 0.8907127627011003\n",
      "Epoch 367, Loss: 0.8840638388847483\n",
      "Epoch 368, Loss: 0.8546863927923399\n",
      "Epoch 369, Loss: 0.867821074765304\n",
      "Epoch 370, Loss: 0.8732089451674757\n",
      "Epoch 371, Loss: 0.864241379088369\n",
      "Epoch 372, Loss: 0.8864606135878069\n",
      "Epoch 373, Loss: 0.878997188189934\n",
      "Epoch 374, Loss: 0.8898109855323002\n",
      "Epoch 375, Loss: 0.8409329776106209\n",
      "Epoch 376, Loss: 0.8492808650279867\n",
      "Epoch 377, Loss: 0.8752567521457014\n",
      "Epoch 378, Loss: 0.9282725987763241\n",
      "Epoch 379, Loss: 0.9010590561505022\n",
      "Epoch 380, Loss: 0.8716912803978756\n",
      "Epoch 381, Loss: 0.8707702427074827\n",
      "Epoch 382, Loss: 0.8798082713680021\n",
      "Epoch 383, Loss: 0.8175256725015312\n",
      "Epoch 384, Loss: 0.8243982339727467\n",
      "Epoch 385, Loss: 0.8360100419356905\n",
      "Epoch 386, Loss: 0.8246791527189058\n",
      "Epoch 387, Loss: 0.8222285180256285\n",
      "Epoch 388, Loss: 0.8285608168306022\n",
      "Epoch 389, Loss: 0.850824158767174\n",
      "Epoch 390, Loss: 0.850646450601775\n",
      "Epoch 391, Loss: 0.8075385437957172\n",
      "Epoch 392, Loss: 0.8381844902860707\n",
      "Epoch 393, Loss: 0.8298528626047331\n",
      "Epoch 394, Loss: 0.8513146474443632\n",
      "Epoch 395, Loss: 0.8497326867333774\n",
      "Epoch 396, Loss: 0.9139510084842813\n",
      "Epoch 397, Loss: 0.7939723884237224\n",
      "Epoch 398, Loss: 0.7790292552832899\n",
      "Epoch 399, Loss: 0.7753500152250816\n",
      "Epoch 400, Loss: 0.8434921420853714\n",
      "Epoch 401, Loss: 0.969254536875363\n",
      "Epoch 402, Loss: 0.9292419963869555\n",
      "Epoch 403, Loss: 0.8209191560745239\n",
      "Epoch 404, Loss: 0.8728025797112234\n",
      "Epoch 405, Loss: 0.8379264905534941\n",
      "Epoch 406, Loss: 0.7996462444806921\n",
      "Epoch 407, Loss: 0.8491333024255161\n",
      "Epoch 408, Loss: 0.8776798433270948\n",
      "Epoch 409, Loss: 0.8483109895525307\n",
      "Epoch 410, Loss: 0.8227793615439842\n",
      "Epoch 411, Loss: 0.825635086873482\n",
      "Epoch 412, Loss: 0.8058066830552858\n",
      "Epoch 413, Loss: 0.9797131912461643\n",
      "Epoch 414, Loss: 0.7827875377803013\n",
      "Epoch 415, Loss: 0.7908522157833494\n",
      "Epoch 416, Loss: 0.8551010181163919\n",
      "Epoch 417, Loss: 0.9571659770505182\n",
      "Epoch 418, Loss: 0.927752176235462\n",
      "Epoch 419, Loss: 0.8921708896242339\n",
      "Epoch 420, Loss: 0.8719265275988085\n",
      "Epoch 421, Loss: 0.812575403986306\n",
      "Epoch 422, Loss: 0.8095721592163218\n",
      "Epoch 423, Loss: 0.7814448075047855\n",
      "Epoch 424, Loss: 0.7747503724591486\n",
      "Epoch 425, Loss: 0.7903890260334673\n",
      "Epoch 426, Loss: 0.8090694875552736\n",
      "Epoch 427, Loss: 0.7803014208530558\n",
      "Epoch 428, Loss: 0.8234798846573665\n",
      "Epoch 429, Loss: 0.7711134481018987\n",
      "Epoch 430, Loss: 0.7207396359279238\n",
      "Epoch 431, Loss: 0.7342695593833923\n",
      "Epoch 432, Loss: 0.7216515356096728\n",
      "Epoch 433, Loss: 0.7049352133582378\n",
      "Epoch 434, Loss: 0.7515114093648976\n",
      "Epoch 435, Loss: 0.759808990462073\n",
      "Epoch 436, Loss: 0.8067119830641253\n",
      "Epoch 437, Loss: 0.7821624268745554\n",
      "Epoch 438, Loss: 0.7693717099469284\n",
      "Epoch 439, Loss: 0.726923662013021\n",
      "Epoch 440, Loss: 0.7286558315671724\n",
      "Epoch 441, Loss: 0.7077095621618731\n",
      "Epoch 442, Loss: 0.6991547346115112\n",
      "Epoch 443, Loss: 0.7067718536689364\n",
      "Epoch 444, Loss: 0.6863327139410479\n",
      "Epoch 445, Loss: 0.6921859856309562\n",
      "Epoch 446, Loss: 0.69970827472621\n",
      "Epoch 447, Loss: 0.6884000404127713\n",
      "Epoch 448, Loss: 0.7013530998394407\n",
      "Epoch 449, Loss: 0.6884010834940548\n",
      "Epoch 450, Loss: 0.6832508455062735\n",
      "Epoch 451, Loss: 0.671123361022308\n",
      "Epoch 452, Loss: 0.6792806931610765\n",
      "Epoch 453, Loss: 0.6896131480562275\n",
      "Epoch 454, Loss: 0.6792322900788538\n",
      "Epoch 455, Loss: 0.738574757658202\n",
      "Epoch 456, Loss: 0.6555599652487656\n",
      "Epoch 457, Loss: 0.6546719618912401\n",
      "Epoch 458, Loss: 0.7189161828879652\n",
      "Epoch 459, Loss: 0.6509544891786987\n",
      "Epoch 460, Loss: 0.6557100864833799\n",
      "Epoch 461, Loss: 0.6809022755458437\n",
      "Epoch 462, Loss: 0.7510668933391571\n",
      "Epoch 463, Loss: 0.6749894259304836\n",
      "Epoch 464, Loss: 0.6495003258359844\n",
      "Epoch 465, Loss: 0.6611452071831144\n",
      "Epoch 466, Loss: 0.6725895764498875\n",
      "Epoch 467, Loss: 0.6513380572713655\n",
      "Epoch 468, Loss: 0.6226084812961775\n",
      "Epoch 469, Loss: 0.6505841417559262\n",
      "Epoch 470, Loss: 0.6829358000179817\n",
      "Epoch 471, Loss: 0.6401944694847896\n",
      "Epoch 472, Loss: 0.6719048865910234\n",
      "Epoch 473, Loss: 0.6131311526586269\n",
      "Epoch 474, Loss: 0.6333116348190554\n",
      "Epoch 475, Loss: 0.6613323986530304\n",
      "Epoch 476, Loss: 0.6526510551058012\n",
      "Epoch 477, Loss: 0.6239864805649067\n",
      "Epoch 478, Loss: 0.6348406867734318\n",
      "Epoch 479, Loss: 0.6224110434795248\n",
      "Epoch 480, Loss: 0.6503310522128796\n",
      "Epoch 481, Loss: 0.6532721067297047\n",
      "Epoch 482, Loss: 0.6482707025675938\n",
      "Epoch 483, Loss: 0.6418620892639818\n",
      "Epoch 484, Loss: 0.6578177624735339\n",
      "Epoch 485, Loss: 0.6522622000554512\n",
      "Epoch 486, Loss: 0.6436607457440475\n",
      "Epoch 487, Loss: 0.6212324762138827\n",
      "Epoch 488, Loss: 0.6149794531279597\n",
      "Epoch 489, Loss: 0.6102569082687641\n",
      "Epoch 490, Loss: 0.6115613487260095\n",
      "Epoch 491, Loss: 0.6019273533903319\n",
      "Epoch 492, Loss: 0.5959095163591976\n",
      "Epoch 493, Loss: 0.6046412032226036\n",
      "Epoch 494, Loss: 0.594475934217716\n",
      "Epoch 495, Loss: 0.5817513805011223\n",
      "Epoch 496, Loss: 0.6437320154288719\n",
      "Epoch 497, Loss: 0.5855967068466646\n",
      "Epoch 498, Loss: 0.592726696154167\n",
      "Epoch 499, Loss: 0.5780466949117595\n",
      "Epoch 500, Loss: 0.5758923736625704\n"
     ]
    }
   ],
   "source": [
    "X_train_encoded = [one_hot_encode(row, len(vocab), word_to_index) for row in train.values]\n",
    "Y_train_encoded = np.array([one_hot_encode_label(label, label_to_index) for label in true_labels_df[\"true_label\"]])\n",
    "\n",
    "X_train = torch.tensor(X_train_encoded, dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array([np.argmax(one_hot) for one_hot in Y_train_encoded]), dtype=torch.long)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = CustomModel(input_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 32\n",
    "dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "generator = torch.Generator().manual_seed(777)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, worker_init_fn=lambda _: np.random.seed(777), generator=generator)\n",
    "\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 76.89%\n",
      "\n",
      "===== Sample Predictions =====\n",
      "Sample 1: True Label = D11, Predicted = D16\n",
      "Sample 2: True Label = D1, Predicted = D20\n",
      "Sample 3: True Label = D3, Predicted = D3\n",
      "Sample 4: True Label = D20, Predicted = D12\n",
      "Sample 5: True Label = D20, Predicted = D12\n",
      "Sample 6: True Label = D20, Predicted = D12\n",
      "Sample 7: True Label = D20, Predicted = D20\n",
      "Sample 8: True Label = D1, Predicted = D20\n",
      "Sample 9: True Label = D20, Predicted = D20\n",
      "Sample 10: True Label = D20, Predicted = D20\n",
      "Sample 11: True Label = D20, Predicted = D20\n",
      "Sample 12: True Label = D12, Predicted = D12\n",
      "Sample 13: True Label = D20, Predicted = D12\n",
      "Sample 14: True Label = D15, Predicted = D15\n",
      "Sample 15: True Label = D15, Predicted = D20\n",
      "Sample 16: True Label = D4, Predicted = D16\n",
      "Sample 17: True Label = D20, Predicted = D20\n",
      "Sample 18: True Label = D20, Predicted = D20\n",
      "Sample 19: True Label = D5, Predicted = D16\n",
      "Sample 20: True Label = D16, Predicted = D16\n",
      "Sample 21: True Label = D3, Predicted = D3\n",
      "Sample 22: True Label = D20, Predicted = D12\n",
      "Sample 23: True Label = D12, Predicted = D12\n",
      "Sample 24: True Label = D16, Predicted = D16\n",
      "Sample 25: True Label = D20, Predicted = D20\n",
      "Sample 26: True Label = D20, Predicted = D20\n",
      "Sample 27: True Label = D20, Predicted = D20\n",
      "Sample 28: True Label = D12, Predicted = D12\n",
      "Sample 29: True Label = D15, Predicted = D20\n",
      "Sample 30: True Label = D12, Predicted = D12\n",
      "Sample 31: True Label = D3, Predicted = D3\n",
      "Sample 32: True Label = D20, Predicted = D20\n",
      "Sample 33: True Label = D15, Predicted = D15\n",
      "Sample 34: True Label = D15, Predicted = D20\n",
      "Sample 35: True Label = D16, Predicted = D16\n",
      "Sample 36: True Label = D15, Predicted = D15\n",
      "Sample 37: True Label = D20, Predicted = D20\n",
      "Sample 38: True Label = D1, Predicted = D1\n",
      "Sample 39: True Label = D20, Predicted = D12\n",
      "Sample 40: True Label = D15, Predicted = D15\n",
      "Sample 41: True Label = D20, Predicted = D20\n",
      "Sample 42: True Label = D1, Predicted = D1\n",
      "Sample 43: True Label = D20, Predicted = D20\n",
      "Sample 44: True Label = D15, Predicted = D16\n",
      "Sample 45: True Label = D1, Predicted = D20\n",
      "Sample 46: True Label = D15, Predicted = D15\n",
      "Sample 47: True Label = D12, Predicted = D12\n",
      "Sample 48: True Label = D1, Predicted = D1\n",
      "Sample 49: True Label = D28, Predicted = D16\n",
      "Sample 50: True Label = D20, Predicted = D20\n",
      "Sample 51: True Label = D15, Predicted = D15\n",
      "Sample 52: True Label = D15, Predicted = D15\n",
      "Sample 53: True Label = D20, Predicted = D16\n",
      "Sample 54: True Label = D16, Predicted = D16\n",
      "Sample 55: True Label = D1, Predicted = D20\n",
      "Sample 56: True Label = D12, Predicted = D12\n",
      "Sample 57: True Label = D12, Predicted = D12\n",
      "Sample 58: True Label = D12, Predicted = D12\n",
      "Sample 59: True Label = D3, Predicted = D3\n",
      "Sample 60: True Label = D20, Predicted = D20\n",
      "Sample 61: True Label = D15, Predicted = D15\n",
      "Sample 62: True Label = D28, Predicted = D16\n",
      "Sample 63: True Label = D12, Predicted = D12\n",
      "Sample 64: True Label = D20, Predicted = D20\n",
      "Sample 65: True Label = D1, Predicted = D1\n",
      "Sample 66: True Label = D20, Predicted = D20\n",
      "Sample 67: True Label = D15, Predicted = D15\n",
      "Sample 68: True Label = D15, Predicted = D15\n",
      "Sample 69: True Label = D20, Predicted = D20\n",
      "Sample 70: True Label = D20, Predicted = D20\n",
      "Sample 71: True Label = D20, Predicted = D20\n",
      "Sample 72: True Label = D20, Predicted = D20\n",
      "Sample 73: True Label = D15, Predicted = D15\n",
      "Sample 74: True Label = D12, Predicted = D12\n",
      "Sample 75: True Label = D12, Predicted = D12\n",
      "Sample 76: True Label = D15, Predicted = D15\n",
      "Sample 77: True Label = D20, Predicted = D20\n",
      "Sample 78: True Label = D15, Predicted = D15\n",
      "Sample 79: True Label = D20, Predicted = D20\n",
      "Sample 80: True Label = D15, Predicted = D15\n",
      "Sample 81: True Label = D16, Predicted = D16\n",
      "Sample 82: True Label = D1, Predicted = D12\n",
      "Sample 83: True Label = D4, Predicted = D4\n",
      "Sample 84: True Label = D12, Predicted = D12\n",
      "Sample 85: True Label = D15, Predicted = D15\n",
      "Sample 86: True Label = D12, Predicted = D12\n",
      "Sample 87: True Label = D20, Predicted = D20\n",
      "Sample 88: True Label = D20, Predicted = D20\n",
      "Sample 89: True Label = D15, Predicted = D15\n",
      "Sample 90: True Label = D12, Predicted = D12\n",
      "Sample 91: True Label = D15, Predicted = D15\n",
      "Sample 92: True Label = D15, Predicted = D15\n",
      "Sample 93: True Label = D20, Predicted = D12\n",
      "Sample 94: True Label = D12, Predicted = D12\n",
      "Sample 95: True Label = D20, Predicted = D20\n",
      "Sample 96: True Label = D12, Predicted = D12\n",
      "Sample 97: True Label = D20, Predicted = D20\n",
      "Sample 98: True Label = D20, Predicted = D20\n",
      "Sample 99: True Label = D3, Predicted = D3\n",
      "Sample 100: True Label = D16, Predicted = D16\n",
      "Sample 101: True Label = D20, Predicted = D20\n",
      "Sample 102: True Label = D20, Predicted = D20\n",
      "Sample 103: True Label = D20, Predicted = D20\n",
      "Sample 104: True Label = D20, Predicted = D20\n",
      "Sample 105: True Label = D20, Predicted = D20\n",
      "Sample 106: True Label = D16, Predicted = D16\n",
      "Sample 107: True Label = D12, Predicted = D12\n",
      "Sample 108: True Label = D20, Predicted = D20\n",
      "Sample 109: True Label = D12, Predicted = D12\n",
      "Sample 110: True Label = D12, Predicted = D12\n",
      "Sample 111: True Label = D20, Predicted = D20\n",
      "Sample 112: True Label = D20, Predicted = D20\n",
      "Sample 113: True Label = D20, Predicted = D20\n",
      "Sample 114: True Label = D12, Predicted = D12\n",
      "Sample 115: True Label = D15, Predicted = D15\n",
      "Sample 116: True Label = D20, Predicted = D20\n",
      "Sample 117: True Label = D1, Predicted = D1\n",
      "Sample 118: True Label = D28, Predicted = D28\n",
      "Sample 119: True Label = D12, Predicted = D12\n",
      "Sample 120: True Label = D16, Predicted = D16\n",
      "Sample 121: True Label = D16, Predicted = D16\n",
      "Sample 122: True Label = D12, Predicted = D12\n",
      "Sample 123: True Label = D15, Predicted = D15\n",
      "Sample 124: True Label = D4, Predicted = D4\n",
      "Sample 125: True Label = D12, Predicted = D12\n",
      "Sample 126: True Label = D20, Predicted = D20\n",
      "Sample 127: True Label = D20, Predicted = D20\n",
      "Sample 128: True Label = D12, Predicted = D12\n",
      "Sample 129: True Label = D12, Predicted = D12\n",
      "Sample 130: True Label = D15, Predicted = D15\n",
      "Sample 131: True Label = D3, Predicted = D3\n",
      "Sample 132: True Label = D12, Predicted = D12\n",
      "Sample 133: True Label = D12, Predicted = D20\n",
      "Sample 134: True Label = D20, Predicted = D20\n",
      "Sample 135: True Label = D12, Predicted = D12\n",
      "Sample 136: True Label = D12, Predicted = D12\n",
      "Sample 137: True Label = D20, Predicted = D20\n",
      "Sample 138: True Label = D20, Predicted = D20\n",
      "Sample 139: True Label = D12, Predicted = D12\n",
      "Sample 140: True Label = D12, Predicted = D12\n",
      "Sample 141: True Label = D20, Predicted = D20\n",
      "Sample 142: True Label = D12, Predicted = D12\n",
      "Sample 143: True Label = D6, Predicted = D16\n",
      "Sample 144: True Label = D3, Predicted = D16\n",
      "Sample 145: True Label = D20, Predicted = D20\n",
      "Sample 146: True Label = D12, Predicted = D12\n",
      "Sample 147: True Label = D17, Predicted = D16\n",
      "Sample 148: True Label = D12, Predicted = D12\n",
      "Sample 149: True Label = D16, Predicted = D16\n",
      "Sample 150: True Label = D15, Predicted = D15\n",
      "Sample 151: True Label = D19, Predicted = D16\n",
      "Sample 152: True Label = D28, Predicted = D20\n",
      "Sample 153: True Label = D12, Predicted = D12\n",
      "Sample 154: True Label = D3, Predicted = D3\n",
      "Sample 155: True Label = D4, Predicted = D16\n",
      "Sample 156: True Label = D20, Predicted = D20\n",
      "Sample 157: True Label = D20, Predicted = D20\n",
      "Sample 158: True Label = D20, Predicted = D12\n",
      "Sample 159: True Label = D12, Predicted = D12\n",
      "Sample 160: True Label = D16, Predicted = D16\n",
      "Sample 161: True Label = D20, Predicted = D12\n",
      "Sample 162: True Label = D12, Predicted = D12\n",
      "Sample 163: True Label = D20, Predicted = D12\n",
      "Sample 164: True Label = D20, Predicted = D20\n",
      "Sample 165: True Label = D20, Predicted = D20\n",
      "Sample 166: True Label = D4, Predicted = D4\n",
      "Sample 167: True Label = D16, Predicted = D16\n",
      "Sample 168: True Label = D12, Predicted = D12\n",
      "Sample 169: True Label = D20, Predicted = D20\n",
      "Sample 170: True Label = D16, Predicted = D16\n",
      "Sample 171: True Label = D20, Predicted = D20\n",
      "Sample 172: True Label = D20, Predicted = D20\n",
      "Sample 173: True Label = D20, Predicted = D20\n",
      "Sample 174: True Label = D1, Predicted = D1\n",
      "Sample 175: True Label = D3, Predicted = D3\n",
      "Sample 176: True Label = D20, Predicted = D20\n",
      "Sample 177: True Label = D12, Predicted = D12\n",
      "Sample 178: True Label = D15, Predicted = D15\n",
      "Sample 179: True Label = D15, Predicted = D15\n",
      "Sample 180: True Label = D3, Predicted = D16\n",
      "Sample 181: True Label = D20, Predicted = D16\n",
      "Sample 182: True Label = D19, Predicted = D16\n",
      "Sample 183: True Label = D17, Predicted = D16\n",
      "Sample 184: True Label = D15, Predicted = D15\n",
      "Sample 185: True Label = D20, Predicted = D20\n",
      "Sample 186: True Label = D13, Predicted = D12\n",
      "Sample 187: True Label = D16, Predicted = D16\n",
      "Sample 188: True Label = D20, Predicted = D12\n",
      "Sample 189: True Label = D3, Predicted = D3\n",
      "Sample 190: True Label = D3, Predicted = D3\n",
      "Sample 191: True Label = D12, Predicted = D12\n",
      "Sample 192: True Label = D20, Predicted = D20\n",
      "Sample 193: True Label = D16, Predicted = D16\n",
      "Sample 194: True Label = D20, Predicted = D12\n",
      "Sample 195: True Label = D12, Predicted = D12\n",
      "Sample 196: True Label = D16, Predicted = D16\n",
      "Sample 197: True Label = D1, Predicted = D20\n",
      "Sample 198: True Label = D20, Predicted = D20\n",
      "Sample 199: True Label = D15, Predicted = D20\n",
      "Sample 200: True Label = D15, Predicted = D1\n",
      "Sample 201: True Label = D15, Predicted = D15\n",
      "Sample 202: True Label = D16, Predicted = D16\n",
      "Sample 203: True Label = D12, Predicted = D12\n",
      "Sample 204: True Label = D15, Predicted = D20\n",
      "Sample 205: True Label = D20, Predicted = D20\n",
      "Sample 206: True Label = D20, Predicted = D20\n",
      "Sample 207: True Label = D3, Predicted = D16\n",
      "Sample 208: True Label = D12, Predicted = D12\n",
      "Sample 209: True Label = D16, Predicted = D16\n",
      "Sample 210: True Label = D16, Predicted = D16\n",
      "Sample 211: True Label = D15, Predicted = D20\n",
      "Sample 212: True Label = D28, Predicted = D28\n",
      "Sample 213: True Label = D15, Predicted = D15\n",
      "Sample 214: True Label = D12, Predicted = D12\n",
      "Sample 215: True Label = D12, Predicted = D12\n",
      "Sample 216: True Label = D20, Predicted = D12\n",
      "Sample 217: True Label = D12, Predicted = D12\n",
      "Sample 218: True Label = D12, Predicted = D12\n",
      "Sample 219: True Label = D16, Predicted = D16\n",
      "Sample 220: True Label = D28, Predicted = D28\n",
      "Sample 221: True Label = D21, Predicted = D21\n",
      "Sample 222: True Label = D12, Predicted = D12\n",
      "Sample 223: True Label = D1, Predicted = D1\n",
      "Sample 224: True Label = D12, Predicted = D12\n",
      "Sample 225: True Label = D12, Predicted = D12\n",
      "Sample 226: True Label = D20, Predicted = D20\n",
      "Sample 227: True Label = D15, Predicted = D15\n",
      "Sample 228: True Label = D15, Predicted = D15\n",
      "Sample 229: True Label = D27, Predicted = D20\n",
      "Sample 230: True Label = D17, Predicted = D16\n",
      "Sample 231: True Label = D12, Predicted = D12\n",
      "Sample 232: True Label = D20, Predicted = D20\n",
      "Sample 233: True Label = D20, Predicted = D20\n",
      "Sample 234: True Label = D4, Predicted = D4\n",
      "Sample 235: True Label = D20, Predicted = D20\n",
      "Sample 236: True Label = D16, Predicted = D16\n",
      "Sample 237: True Label = D16, Predicted = D16\n",
      "Sample 238: True Label = D20, Predicted = D20\n",
      "Sample 239: True Label = D12, Predicted = D12\n",
      "Sample 240: True Label = D20, Predicted = D20\n",
      "Sample 241: True Label = D15, Predicted = D15\n",
      "Sample 242: True Label = D15, Predicted = D20\n",
      "Sample 243: True Label = D12, Predicted = D12\n",
      "Sample 244: True Label = D15, Predicted = D15\n",
      "Sample 245: True Label = D20, Predicted = D12\n",
      "Sample 246: True Label = D6, Predicted = D6\n",
      "Sample 247: True Label = D20, Predicted = D20\n",
      "Sample 248: True Label = D1, Predicted = D1\n",
      "Sample 249: True Label = D20, Predicted = D20\n",
      "Sample 250: True Label = D12, Predicted = D12\n",
      "Sample 251: True Label = D20, Predicted = D20\n",
      "Sample 252: True Label = D13, Predicted = D16\n",
      "Sample 253: True Label = D15, Predicted = D15\n",
      "Sample 254: True Label = D20, Predicted = D12\n",
      "Sample 255: True Label = D15, Predicted = D15\n",
      "Sample 256: True Label = D12, Predicted = D12\n",
      "Sample 257: True Label = D15, Predicted = D20\n",
      "Sample 258: True Label = D15, Predicted = D15\n",
      "Sample 259: True Label = D20, Predicted = D12\n",
      "Sample 260: True Label = D20, Predicted = D12\n",
      "Sample 261: True Label = D12, Predicted = D12\n",
      "Sample 262: True Label = D20, Predicted = D12\n",
      "Sample 263: True Label = D6, Predicted = D6\n",
      "Sample 264: True Label = D20, Predicted = D20\n",
      "Sample 265: True Label = D12, Predicted = D12\n",
      "Sample 266: True Label = D15, Predicted = D15\n",
      "Sample 267: True Label = D20, Predicted = D20\n",
      "Sample 268: True Label = D20, Predicted = D12\n",
      "Sample 269: True Label = D15, Predicted = D15\n",
      "Sample 270: True Label = D7, Predicted = D16\n",
      "Sample 271: True Label = D15, Predicted = D15\n",
      "Sample 272: True Label = D20, Predicted = D20\n",
      "Sample 273: True Label = D27, Predicted = D20\n",
      "Sample 274: True Label = D17, Predicted = D16\n",
      "Sample 275: True Label = D11, Predicted = D16\n",
      "Sample 276: True Label = D15, Predicted = D15\n",
      "Sample 277: True Label = D17, Predicted = D11\n",
      "Sample 278: True Label = D15, Predicted = D20\n",
      "Sample 279: True Label = D20, Predicted = D20\n",
      "Sample 280: True Label = D20, Predicted = D12\n",
      "Sample 281: True Label = D15, Predicted = D15\n",
      "Sample 282: True Label = D12, Predicted = D12\n",
      "Sample 283: True Label = D20, Predicted = D12\n",
      "Sample 284: True Label = D12, Predicted = D12\n",
      "Sample 285: True Label = D20, Predicted = D20\n",
      "Sample 286: True Label = D20, Predicted = D20\n",
      "Sample 287: True Label = D12, Predicted = D12\n",
      "Sample 288: True Label = D15, Predicted = D15\n",
      "Sample 289: True Label = D20, Predicted = D12\n",
      "Sample 290: True Label = D20, Predicted = D20\n",
      "Sample 291: True Label = D16, Predicted = D16\n",
      "Sample 292: True Label = D12, Predicted = D12\n",
      "Sample 293: True Label = D28, Predicted = D20\n",
      "Sample 294: True Label = D1, Predicted = D12\n",
      "Sample 295: True Label = D12, Predicted = D12\n",
      "Sample 296: True Label = D15, Predicted = D15\n",
      "Sample 297: True Label = D12, Predicted = D12\n",
      "Sample 298: True Label = D16, Predicted = D16\n",
      "Sample 299: True Label = D15, Predicted = D15\n",
      "Sample 300: True Label = D12, Predicted = D20\n",
      "Sample 301: True Label = D28, Predicted = D28\n",
      "Sample 302: True Label = D20, Predicted = D20\n",
      "Sample 303: True Label = D3, Predicted = D12\n",
      "Sample 304: True Label = D3, Predicted = D1\n",
      "Sample 305: True Label = D20, Predicted = D20\n",
      "Sample 306: True Label = D20, Predicted = D12\n",
      "Sample 307: True Label = D12, Predicted = D12\n",
      "Sample 308: True Label = D1, Predicted = D1\n",
      "Sample 309: True Label = D20, Predicted = D20\n",
      "Sample 310: True Label = D1, Predicted = D1\n",
      "Sample 311: True Label = D20, Predicted = D20\n",
      "Sample 312: True Label = D20, Predicted = D20\n",
      "Sample 313: True Label = D1, Predicted = D15\n",
      "Sample 314: True Label = D1, Predicted = D1\n",
      "Sample 315: True Label = D20, Predicted = D20\n",
      "Sample 316: True Label = D16, Predicted = D16\n",
      "Sample 317: True Label = D12, Predicted = D12\n",
      "Sample 318: True Label = D12, Predicted = D20\n",
      "Sample 319: True Label = D27, Predicted = D16\n",
      "Sample 320: True Label = D20, Predicted = D12\n",
      "Sample 321: True Label = D16, Predicted = D16\n",
      "Sample 322: True Label = D3, Predicted = D3\n",
      "Sample 323: True Label = D20, Predicted = D20\n",
      "Sample 324: True Label = D12, Predicted = D12\n",
      "Sample 325: True Label = D20, Predicted = D12\n",
      "Sample 326: True Label = D1, Predicted = D1\n",
      "Sample 327: True Label = D12, Predicted = D12\n",
      "Sample 328: True Label = D5, Predicted = D5\n",
      "Sample 329: True Label = D17, Predicted = D1\n",
      "Sample 330: True Label = D16, Predicted = D16\n",
      "Sample 331: True Label = D16, Predicted = D5\n",
      "Sample 332: True Label = D20, Predicted = D20\n",
      "Sample 333: True Label = D12, Predicted = D12\n",
      "Sample 334: True Label = D4, Predicted = D4\n",
      "Sample 335: True Label = D15, Predicted = D15\n",
      "Sample 336: True Label = D12, Predicted = D12\n",
      "Sample 337: True Label = D15, Predicted = D15\n",
      "Sample 338: True Label = D16, Predicted = D16\n",
      "Sample 339: True Label = D12, Predicted = D12\n",
      "Sample 340: True Label = D12, Predicted = D12\n",
      "Sample 341: True Label = D15, Predicted = D15\n",
      "Sample 342: True Label = D20, Predicted = D12\n",
      "Sample 343: True Label = D15, Predicted = D15\n",
      "Sample 344: True Label = D28, Predicted = D20\n",
      "Sample 345: True Label = D3, Predicted = D16\n",
      "Sample 346: True Label = D12, Predicted = D12\n",
      "Sample 347: True Label = D1, Predicted = D1\n",
      "Sample 348: True Label = D12, Predicted = D12\n",
      "Sample 349: True Label = D20, Predicted = D20\n",
      "Sample 350: True Label = D28, Predicted = D28\n",
      "Sample 351: True Label = D12, Predicted = D12\n",
      "Sample 352: True Label = D20, Predicted = D20\n",
      "Sample 353: True Label = D20, Predicted = D20\n",
      "Sample 354: True Label = D4, Predicted = D4\n",
      "Sample 355: True Label = D1, Predicted = D20\n",
      "Sample 356: True Label = D15, Predicted = D15\n",
      "Sample 357: True Label = D3, Predicted = D20\n",
      "Sample 358: True Label = D20, Predicted = D20\n",
      "Sample 359: True Label = D16, Predicted = D16\n",
      "Sample 360: True Label = D20, Predicted = D20\n",
      "Sample 361: True Label = D12, Predicted = D12\n",
      "Sample 362: True Label = D20, Predicted = D12\n",
      "Sample 363: True Label = D1, Predicted = D12\n",
      "Sample 364: True Label = D20, Predicted = D20\n",
      "Sample 365: True Label = D20, Predicted = D20\n",
      "Sample 366: True Label = D15, Predicted = D15\n",
      "Sample 367: True Label = D28, Predicted = D28\n",
      "Sample 368: True Label = D15, Predicted = D15\n",
      "Sample 369: True Label = D16, Predicted = D16\n",
      "Sample 370: True Label = D15, Predicted = D15\n",
      "Sample 371: True Label = D3, Predicted = D16\n",
      "Sample 372: True Label = D20, Predicted = D20\n",
      "Sample 373: True Label = D20, Predicted = D20\n",
      "Sample 374: True Label = D20, Predicted = D20\n",
      "Sample 375: True Label = D32, Predicted = D16\n",
      "Sample 376: True Label = D15, Predicted = D15\n",
      "Sample 377: True Label = D15, Predicted = D15\n",
      "Sample 378: True Label = D20, Predicted = D20\n",
      "Sample 379: True Label = D3, Predicted = D3\n",
      "Sample 380: True Label = D20, Predicted = D20\n",
      "Sample 381: True Label = D20, Predicted = D20\n",
      "Sample 382: True Label = D11, Predicted = D16\n",
      "Sample 383: True Label = D28, Predicted = D16\n",
      "Sample 384: True Label = D12, Predicted = D12\n",
      "Sample 385: True Label = D20, Predicted = D12\n",
      "Sample 386: True Label = D4, Predicted = D16\n",
      "Sample 387: True Label = D15, Predicted = D15\n",
      "Sample 388: True Label = D28, Predicted = D16\n",
      "Sample 389: True Label = D12, Predicted = D12\n",
      "Sample 390: True Label = D12, Predicted = D12\n",
      "Sample 391: True Label = D12, Predicted = D12\n",
      "Sample 392: True Label = D20, Predicted = D20\n",
      "Sample 393: True Label = D20, Predicted = D20\n",
      "Sample 394: True Label = D17, Predicted = D17\n",
      "Sample 395: True Label = D1, Predicted = D16\n",
      "Sample 396: True Label = D3, Predicted = D16\n",
      "Sample 397: True Label = D3, Predicted = D16\n",
      "Sample 398: True Label = D1, Predicted = D1\n",
      "Sample 399: True Label = D20, Predicted = D12\n",
      "Sample 400: True Label = D12, Predicted = D12\n",
      "Sample 401: True Label = D12, Predicted = D12\n",
      "Sample 402: True Label = D28, Predicted = D15\n",
      "Sample 403: True Label = D28, Predicted = D28\n",
      "Sample 404: True Label = D4, Predicted = D16\n",
      "Sample 405: True Label = D15, Predicted = D15\n",
      "Sample 406: True Label = D12, Predicted = D12\n",
      "Sample 407: True Label = D20, Predicted = D12\n",
      "Sample 408: True Label = D20, Predicted = D20\n",
      "Sample 409: True Label = D15, Predicted = D15\n",
      "Sample 410: True Label = D11, Predicted = D11\n",
      "Sample 411: True Label = D12, Predicted = D12\n",
      "Sample 412: True Label = D20, Predicted = D12\n",
      "Sample 413: True Label = D20, Predicted = D20\n",
      "Sample 414: True Label = D20, Predicted = D20\n",
      "Sample 415: True Label = D15, Predicted = D15\n",
      "Sample 416: True Label = D20, Predicted = D20\n",
      "Sample 417: True Label = D16, Predicted = D16\n",
      "Sample 418: True Label = D28, Predicted = D20\n",
      "Sample 419: True Label = D12, Predicted = D12\n",
      "Sample 420: True Label = D12, Predicted = D12\n",
      "Sample 421: True Label = D1, Predicted = D20\n",
      "Sample 422: True Label = D5, Predicted = D16\n",
      "Sample 423: True Label = D12, Predicted = D12\n",
      "Sample 424: True Label = D15, Predicted = D15\n",
      "Sample 425: True Label = D15, Predicted = D15\n",
      "Sample 426: True Label = D3, Predicted = D20\n",
      "Sample 427: True Label = D15, Predicted = D15\n",
      "Sample 428: True Label = D12, Predicted = D12\n",
      "Sample 429: True Label = D20, Predicted = D20\n",
      "Sample 430: True Label = D1, Predicted = D16\n",
      "Sample 431: True Label = D15, Predicted = D15\n",
      "Sample 432: True Label = D28, Predicted = D16\n",
      "Sample 433: True Label = D3, Predicted = D16\n",
      "Sample 434: True Label = D15, Predicted = D15\n",
      "Sample 435: True Label = D15, Predicted = D15\n",
      "Sample 436: True Label = D16, Predicted = D16\n",
      "Sample 437: True Label = D12, Predicted = D12\n",
      "Sample 438: True Label = D16, Predicted = D16\n",
      "Sample 439: True Label = D16, Predicted = D16\n",
      "Sample 440: True Label = D20, Predicted = D12\n",
      "Sample 441: True Label = D28, Predicted = D20\n",
      "Sample 442: True Label = D1, Predicted = D1\n",
      "Sample 443: True Label = D20, Predicted = D20\n",
      "Sample 444: True Label = D12, Predicted = D12\n",
      "Sample 445: True Label = D20, Predicted = D20\n",
      "Sample 446: True Label = D3, Predicted = D15\n",
      "Sample 447: True Label = D18, Predicted = D18\n",
      "Sample 448: True Label = D12, Predicted = D12\n",
      "Sample 449: True Label = D1, Predicted = D1\n",
      "Sample 450: True Label = D20, Predicted = D20\n",
      "Sample 451: True Label = D5, Predicted = D20\n",
      "Sample 452: True Label = D12, Predicted = D12\n",
      "Sample 453: True Label = D12, Predicted = D12\n",
      "Sample 454: True Label = D12, Predicted = D12\n",
      "Sample 455: True Label = D20, Predicted = D20\n",
      "Sample 456: True Label = D3, Predicted = D3\n",
      "Sample 457: True Label = D12, Predicted = D12\n",
      "Sample 458: True Label = D15, Predicted = D15\n",
      "Sample 459: True Label = D3, Predicted = D16\n",
      "Sample 460: True Label = D12, Predicted = D12\n",
      "Sample 461: True Label = D20, Predicted = D20\n",
      "Sample 462: True Label = D15, Predicted = D15\n",
      "Sample 463: True Label = D16, Predicted = D16\n",
      "Sample 464: True Label = D1, Predicted = D1\n",
      "Sample 465: True Label = D20, Predicted = D12\n",
      "Sample 466: True Label = D15, Predicted = D15\n",
      "Sample 467: True Label = D28, Predicted = D16\n",
      "Sample 468: True Label = D20, Predicted = D20\n",
      "Sample 469: True Label = D15, Predicted = D15\n",
      "Sample 470: True Label = D27, Predicted = D16\n",
      "Sample 471: True Label = D12, Predicted = D12\n",
      "Sample 472: True Label = D12, Predicted = D12\n",
      "Sample 473: True Label = D15, Predicted = D20\n",
      "Sample 474: True Label = D4, Predicted = D16\n",
      "Sample 475: True Label = D20, Predicted = D20\n",
      "Sample 476: True Label = D12, Predicted = D12\n",
      "Sample 477: True Label = D20, Predicted = D20\n",
      "Sample 478: True Label = D20, Predicted = D20\n",
      "Sample 479: True Label = D11, Predicted = D11\n",
      "Sample 480: True Label = D19, Predicted = D19\n",
      "Sample 481: True Label = D1, Predicted = D20\n",
      "Sample 482: True Label = D28, Predicted = D28\n",
      "Sample 483: True Label = D12, Predicted = D12\n",
      "Sample 484: True Label = D15, Predicted = D15\n",
      "Sample 485: True Label = D15, Predicted = D15\n",
      "Sample 486: True Label = D16, Predicted = D16\n",
      "Sample 487: True Label = D15, Predicted = D16\n",
      "Sample 488: True Label = D20, Predicted = D20\n",
      "Sample 489: True Label = D16, Predicted = D16\n",
      "Sample 490: True Label = D15, Predicted = D20\n",
      "Sample 491: True Label = D12, Predicted = D12\n",
      "Sample 492: True Label = D20, Predicted = D12\n",
      "Sample 493: True Label = D12, Predicted = D12\n",
      "Sample 494: True Label = D12, Predicted = D12\n",
      "Sample 495: True Label = D3, Predicted = D3\n",
      "Sample 496: True Label = D20, Predicted = D12\n",
      "Sample 497: True Label = D12, Predicted = D12\n",
      "Sample 498: True Label = D4, Predicted = D4\n",
      "Sample 499: True Label = D15, Predicted = D20\n",
      "Sample 500: True Label = D4, Predicted = D4\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가 함수\n",
    "def evaluate_model(model, X_train, y_train, label_vocab):\n",
    "    model.eval()  # 평가 모드\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_train)\n",
    "        predictions = torch.argmax(outputs, dim=1)  # 예측값 (정수 인덱스)\n",
    "\n",
    "        # y_train이 원핫 벡터인지 확인 후 변환\n",
    "        if y_train.dim() > 1:\n",
    "            y_train = torch.argmax(y_train, dim=1)\n",
    "\n",
    "        correct = (predictions == y_train).sum().item()  # 정답 개수\n",
    "        accuracy = correct / len(y_train) * 100  # Accuracy 계산\n",
    "\n",
    "    print(f\"Train Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # 일부 샘플 출력\n",
    "    print(\"\\n===== Sample Predictions =====\")\n",
    "    for i in range(500):\n",
    "        true_label = label_vocab[y_train[i].item()]\n",
    "        pred_label = label_vocab[predictions[i].item()]\n",
    "        print(f\"Sample {i+1}: True Label = {true_label}, Predicted = {pred_label}\")\n",
    "\n",
    "# Accuracy 평가 실행\n",
    "evaluate_model(model, X_train, y_train, label_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label to index mapping: {'D1': 0, 'D11': 1, 'D12': 2, 'D13': 3, 'D15': 4, 'D16': 5, 'D17': 6, 'D18': 7, 'D19': 8, 'D20': 9, 'D21': 10, 'D27': 11, 'D28': 12, 'D3': 13, 'D32': 14, 'D4': 15, 'D5': 16, 'D6': 17, 'D7': 18}\n"
     ]
    }
   ],
   "source": [
    "print(\"Label to index mapping:\", label_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: D11, One-Hot: [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Label: D1, One-Hot: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Label: D3, One-Hot: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Label: D20, One-Hot: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Label: D20, One-Hot: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Label: D20, One-Hot: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Label: D20, One-Hot: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Label: D1, One-Hot: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Label: D20, One-Hot: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Label: D20, One-Hot: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# true_labels_df에서 변환된 Y_train_encoded 확인\n",
    "for label in list(true_labels_df[\"true_label\"])[:10]:  # 10개 샘플 확인\n",
    "    one_hot_label = one_hot_encode_label(label, label_to_index)\n",
    "    print(f\"Label: {label}, One-Hot: {one_hot_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   true_label\n",
      "0         D11\n",
      "1          D1\n",
      "2          D3\n",
      "3         D20\n",
      "4         D20\n",
      "5         D20\n",
      "6         D20\n",
      "7          D1\n",
      "8         D20\n",
      "9         D20\n",
      "10        D20\n",
      "11        D12\n",
      "12        D20\n",
      "13        D15\n",
      "14        D15\n",
      "15         D4\n",
      "16        D20\n",
      "17        D20\n",
      "18         D5\n",
      "19        D16\n",
      "true_label\n",
      "D20    271\n",
      "D12    200\n",
      "D15    143\n",
      "D1      81\n",
      "D16     61\n",
      "D3      49\n",
      "D28     30\n",
      "D4      18\n",
      "D17     10\n",
      "D5       8\n",
      "D11      7\n",
      "D27      6\n",
      "D19      5\n",
      "D6       3\n",
      "D13      3\n",
      "D18      2\n",
      "D21      1\n",
      "D7       1\n",
      "D32      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(true_labels_df.head(20))  # 처음 20개의 true label 출력\n",
    "print(true_labels_df['true_label'].value_counts())  # 각 라벨 개수 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Encoded One-Hot Vector =====\n",
      "[1662, 397, 1044, 3, 4]\n",
      "\n",
      "===== Decoded Words =====\n",
      "[['W42', 'W17', 'W31', 'W10', 'W100']]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(row, vocab_size, word_to_index, max_seq_length=20):\n",
    "    \"\"\"\n",
    "    단어 등장 순서를 유지하는 원핫 벡터 변환 함수\n",
    "    \"\"\"\n",
    "    word_indices = []\n",
    "    for word in row[:max_seq_length]:  # 최대 길이만큼 단어 처리\n",
    "        word = word if word in word_to_index else \"UNK\"\n",
    "        if word != \"PAD\":\n",
    "            word_indices.append(word_to_index[word])  # 순서 유지한 채 저장\n",
    "    return word_indices  # 단어 인덱스 리스트 반환\n",
    "\n",
    "def decode_one_hot(encoded_indices, word_to_index):\n",
    "    \"\"\"\n",
    "    원핫 벡터로 변환된 인덱스 리스트를 다시 단어 시퀀스로 변환\n",
    "    \"\"\"\n",
    "    index_to_word = {i: word for word, i in word_to_index.items()}  # 인덱스를 단어로 변환\n",
    "    words = [[index_to_word[i] for i in encoded_row if i in index_to_word] for encoded_row in encoded_indices]\n",
    "    return words\n",
    "\n",
    "\n",
    "# 테스트 문장 (임의로 선정)\n",
    "test_sentence = [\"W42\", \"W17\", \"W31\", \"W10\", \"W100\"]\n",
    "test_encoded = one_hot_encode(test_sentence, len(vocab), word_to_index)\n",
    "\n",
    "print(\"\\n===== Encoded One-Hot Vector =====\")\n",
    "print(test_encoded)\n",
    "test_decoded = decode_one_hot([test_encoded], word_to_index)\n",
    "\n",
    "print(\"\\n===== Decoded Words =====\")\n",
    "print(test_decoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDL",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
